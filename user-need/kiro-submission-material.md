## Project name
LearningSong

## Elevator pitch
LearningSong transforms educational content into memorable songs using AI. Paste your study material, and let ChatGPT converts it into singable lyrics. You can get two song generated by suno based with your favorate style. With karaoke-style synchronized lyrics, learning becomes an experience you'll actually remember.

## About the project

### Inspiration
We've all struggled to memorize dry educational content. Songs stick in our heads effortlessly—why not harness that for learning? LearningSong was born from the idea that AI could bridge the gap between boring study material and memorable musical experiences.

### What it does
LearningSong is a 3-page web app that:
1. **Page A (Text Input)**: Users paste educational content (up to 10,000 words). Optional Google Search grounding enriches short queries.
2. **Page B (Lyrics Editing)**: AI-generated lyrics appear for review and editing. Users select from 8 music styles (Pop, Rap, Folk, Electronic, Rock, Jazz, Children's, Classical).
3. **Page C (Song Playback)**: Suno API generates two song variations. Users switch between versions, enjoy karaoke-style synchronized lyrics with word-level highlighting, and can adjust timing offset for perfect sync.

### How we built it
We built LearningSong entirely through spec-driven development with Kiro, creating 10 comprehensive specs from project setup to E2E testing:

1. **project-setup**: Foundation—React/FastAPI architecture, Firebase integration, dev environment
2. **page-a-text-input**: Home page—text input, Google Search grounding toggle, rate limit display
3. **page-b-lyrics-editing**: Lyrics editor—AI-generated lyrics, 8 music style selection, song generation
4. **page-c-song-playback**: Playback page—audio player, basic lyrics display, song metadata
5. **dual-song-selection**: Dual variations—SongSwitcher component, variation storage, user preference persistence
6. **timestamped-lyrics-sync**: Karaoke sync—word-level highlighting, binary search for O(log n) lookup, auto-scroll
7. **song-playback-improvements**: Offset adjustment, song history, LRC export
8. **page-b-debugging**: Debugging pipeline issues and UI refinements
9. **e2e-chrome-devtools-testing**: End-to-end testing with Chrome DevTools MCP
10. **implementation-analysis**: Cross-cutting concerns and architecture review

Each spec followed the same rigorous structure: requirements.md (EARS-compliant acceptance criteria) → design.md (architecture, components, correctness properties) → tasks.md (implementation checklist). This systematic approach meant Kiro could implement complex features like dual-song selection (28 correctness properties) and timestamped lyrics sync with minimal back-and-forth—the specs caught edge cases before code was written.

The tech stack:
- **Frontend**: React 19 + TypeScript, Vite, TailwindCSS + shadcn/ui, Zustand, TanStack Query
- **Backend**: FastAPI (Python), LangChain/LangGraph for AI pipeline
- **External**: Suno API (music generation), Firebase (auth, storage), Google Search API

### Challenges we ran into
1. **Lyrics timing sync**: Suno's timestamped lyrics had consistent offset issues. We solved this with a user-adjustable offset slider (-2000ms to +2000ms).
2. **Dual song handling**: Suno generates 2 songs per request, but we initially only showed one. Building the SongSwitcher component required careful state management for audio player, lyrics sync, and user preferences.
3. **E2E testing complexity**: Testing a multi-page flow with WebSocket updates and audio playback required custom Chrome DevTools MCP integration.

### Accomplishments that we're proud of
- **10 complete specs** covering every major feature from project setup to E2E testing
- **Property-based testing** with Hypothesis (Python) and fast-check (TypeScript) ensuring correctness across edge cases
- **Karaoke-style lyrics** with word-level highlighting and smooth auto-scroll
- **Dual song selection** letting users compare and choose their preferred AI-generated version

### What we learned
Spec-driven development fundamentally changes how you build software. Writing requirements and correctness properties upfront forces you to think through edge cases before coding. Kiro's ability to implement from specs meant we spent more time designing and less time debugging.

### What's next for LearningSong
- PDF/DOCX upload support
- Multi-language song generation
- User accounts with song history beyond 48 hours
- AI-generated explanation videos synced with songs

## Built with
React, TypeScript, Vite, TailwindCSS, shadcn/ui, Zustand, TanStack Query, FastAPI, Python, LangChain, LangGraph, Firebase, Suno API, Google Search API, Jest, pytest, Hypothesis, WebSocket, Socket.IO


## How was Kiro used in your project?
Kiro was the ONLY development partner throughout the entire project. We used all four key Kiro features:

1. **Spec-driven development**: Created 10 comprehensive specs covering project setup, all 3 pages, dual-song selection, timestamped lyrics sync, song playback improvements, and E2E testing
2. **Steering docs**: Three concise steering files (product.md, structure.md, tech.md) kept Kiro aligned with our architecture and conventions
3. **Agent hooks**: Automated test reporting and linting workflows
4. **MCP**: fetch, Context7, Chrome DevTools integration to figure out stubbern errorss

## Vibe coding: How did you structure your conversations with Kiro to build your project? What was the most impressive code generation Kiro helped you with?
We used vibe coding primarily for quick fixes and exploratory work. The most impressive generation was the complete LyricsDisplay component with word-level highlighting, binary search for O(log n) timestamp lookup, and smooth auto-scroll with manual scroll detection—all generated from a single conversation describing the karaoke-style behavior we wanted.

## Agent hooks: What specific workflows did you automate with Kiro hooks? How did these hooks improve your development process?
We created 4 agent hooks:

1. **ESLint Report Generator**: Runs ESLint, saves raw output to `./temp/`, generates formatted checklist in `./report/lint-checking/` with issues grouped by file and prioritized (Urgent → Low Risk)
2. **Oxlint Report Generator**: Fast linting for daily development
3. **Frontend Test Report**: Runs Jest tests, generates timestamped reports with errors organized as todo lists
4. **Backend Test Report**: Runs pytest with coverage, generates comprehensive test reports

These hooks transformed our workflow—instead of manually running tests and parsing output, we click a button and get actionable reports. The prioritized error lists made fixing issues systematic rather than chaotic.

## Spec-driven development: How did you structure your spec for Kiro to implement? How did the spec-driven approach improve your development process? How did this compare to vibe coding?

**Spec Structure (3-document pattern for each feature):**

Each of our 10 specs followed a rigorous 3-document structure:

1. **requirements.md** — EARS-compliant acceptance criteria organized by user stories
   - Used formal WHEN/THEN/SHALL syntax for unambiguous requirements
   - Example: "WHEN the Suno API completes a generation task THEN the system SHALL retrieve both song variations from the response"
   - Included glossary defining domain terms (Song Variation, Primary Song, Audio ID, etc.)

2. **design.md** — Technical blueprint with correctness properties
   - Architecture diagrams (Mermaid sequence diagrams showing component interactions)
   - Component interfaces with TypeScript/Python type definitions
   - Data models for both frontend (Zustand stores) and backend (Firestore schema)
   - Correctness properties: universally quantified statements like "For any song with exactly 2 variations, the song switcher component should be rendered"
   - Each property linked to specific requirements (e.g., "Validates: Requirements 2.1")

3. **tasks.md** — Numbered implementation checklist
   - Hierarchical tasks with sub-tasks (e.g., 2.1, 2.2, 2.3)
   - Each task referenced specific requirements
   - Property-based tests included as sub-tasks

**The 10 specs we built (in order):**
1. project-setup → 2. page-a-text-input → 3. page-b-lyrics-editing → 4. page-c-song-playback → 5. dual-song-selection → 6. timestamped-lyrics-sync → 7. song-playback-improvements → 8. page-b-debugging → 9. e2e-chrome-devtools-testing → 10. implementation-analysis

**How spec-driven improved development:**
- Edge cases caught before coding (dual-song-selection had 28 correctness properties covering offline scenarios, malformed API responses, concurrent switch requests)
- Kiro implemented features systematically—no "what should happen when..." questions mid-implementation
- Requirements traceability: every line of code linked back to a specific acceptance criterion

**Comparison to vibe coding:**
Vibe coding worked for quick fixes and exploratory work. But for complex features like dual-song-selection (10 requirements, 28 properties, ~50 tasks), spec-driven was dramatically more effective. Vibe coding would have required constant clarification and produced inconsistent results. With specs, Kiro executed the entire feature in one focused session.

## Steering docs: How did you leverage steering to improve Kiro's responses? Was there a particular strategy that made the biggest difference?
We created 3 steering files in `.kiro/steering/`:

1. **product.md**: Core flow, features, MVP constraints (anonymous auth, 3 songs/day, 48-hour retention)
2. **structure.md**: Project layout, frontend/backend directory structure, naming conventions
3. **tech.md**: Technology stack, quick commands, dev workflow

The biggest difference came from **structure.md**. Before adding it, Kiro would sometimes create files in wrong directories or use inconsistent import paths. After adding the structure steering with the `@/` alias convention and clear directory purposes, every generated file landed exactly where it should.

## MCP: How did extending Kiro's capabilities help you build your project? What sort of features or workflow improvements did MCP enable that otherwise would have been difficult or impossible?
We integrated 3 MCP servers that extended Kiro's capabilities:

**1. Fetch MCP** — External API documentation access
- Fetched Suno API documentation to understand response formats and endpoints
- Retrieved library docs (TanStack Query, Zustand) for correct usage patterns
- Enabled Kiro to work with up-to-date API specs without manual copy-paste

**2. Context7 MCP** — Library-specific knowledge
- Provided accurate, version-specific documentation for React 19, FastAPI, and shadcn/ui
- Helped resolve breaking changes between library versions
- Reduced hallucination on API usage—Kiro generated correct code on first try

**3. Chrome DevTools MCP** — E2E testing and debugging
- Visual debugging: Take screenshots at each test step, inspect element states
- Network monitoring: List and inspect API requests during test flows
- Console monitoring: Capture JavaScript errors and warnings
- Page navigation: Automate multi-page user journeys

The Chrome DevTools MCP was essential for testing the complete user flow: paste content → generate lyrics → edit → generate song → switch variations → play with synced lyrics. Without it, we would have needed separate Playwright/Puppeteer scripts outside Kiro's context, losing the ability to iterate on tests conversationally.
